{
 "metadata": {
  "name": "",
  "signature": "sha256:2270531d5c7b9361a19ee754a05fcc795b3fa2587a161bc570f69374e57e83e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.streaming import StreamingContext\n",
      "from pyspark.streaming.kafka import KafkaUtils\n",
      "ssc = StreamingContext(sc, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.tree import DecisionTreeModel\n",
      "model = DecisionTreeModel.load(sc, \"../mongodb-demo/TwitterDecisionTree\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.predict([0, 1, 0, 4, 18, 2503, 1858, 2043])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd = sc.parallelize([[0, 1, 0, 4, 18, 2503, 1858, 2043]]*10)\n",
      "model.predict(rdd).collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LANG_CODES = ['und', # 'undefined' is 0\n",
      "              'ab', 'aa', 'af', 'ak', 'sq', 'am', 'ar', 'an', 'hy',\n",
      "              'as', 'av', 'ae', 'ay', 'az', 'bm', 'ba', 'eu', 'be',\n",
      "              'bn', 'bh', 'bi', 'bs', 'br', 'bg', 'my', 'ca', 'ch',\n",
      "              'ce', 'ny', 'zh', 'cv', 'kw', 'co', 'cr', 'hr', 'cs',\n",
      "              'da', 'dv', 'nl', 'dz', 'en', 'eo', 'et', 'ee', 'fo',\n",
      "              'fj', 'fi', 'fr', 'ff', 'gl', 'ka', 'de', 'el', 'gn',\n",
      "              'gu', 'ht', 'ha', 'he', 'hz', 'hi', 'ho', 'hu', 'ia',\n",
      "              'id', 'ie', 'ga', 'ig', 'ik', 'io', 'is', 'it', 'iu',\n",
      "              'ja', 'jv', 'kl', 'kn', 'kr', 'ks', 'kk', 'km', 'ki',\n",
      "              'rw', 'ky', 'kv', 'kg', 'ko', 'ku', 'kj', 'la', 'lb',\n",
      "              'lg', 'li', 'ln', 'lo', 'lt', 'lu', 'lv', 'gv', 'mk',\n",
      "              'mg', 'ms', 'ml', 'mt', 'mi', 'mr', 'mh', 'mn', 'na',\n",
      "              'nv', 'nd', 'ne', 'ng', 'nb', 'nn', 'no', 'ii', 'nr',\n",
      "              'oc', 'oj', 'cu', 'om', 'or', 'os', 'pa', 'pi', 'fa',\n",
      "              'pl', 'ps', 'pt', 'qu', 'rm', 'rn', 'ro', 'ru', 'sa',\n",
      "              'sc', 'sd', 'se', 'sm', 'sg', 'sr', 'gd', 'sn', 'si',\n",
      "              'sk', 'sl', 'so', 'st', 'es', 'su', 'sw', 'ss', 'sv',\n",
      "              'ta', 'te', 'tg', 'th', 'ti', 'bo', 'tk', 'tl', 'tn',\n",
      "              'to', 'tr', 'ts', 'tt', 'tw', 'ty', 'ug', 'uk', 'ur',\n",
      "              'uz', 've', 'vi', 'vo', 'wa', 'cy', 'wo', 'fy', 'xh',\n",
      "              'yi', 'yo', 'za', 'zu', 'in', 'iw', 'ckb']\n",
      "codeOf = {float(i): code for i, code in enumerate(LANG_CODES)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import elasticsearch\n",
      "import json\n",
      "def tagAndStore(rdd):\n",
      "    es = elasticsearch.Elasticsearch()\n",
      "    def toDict(record):\n",
      "        return json.loads(record[1])\n",
      "    processed = rdd.map(toDict).cache()\n",
      "    def toFeatures(r):\n",
      "        return [len(r['entities']['hashtags']),\n",
      "              len(r['entities']['user_mentions']),\n",
      "              len(r['entities']['urls']),\n",
      "              len(r['text'].split()),\n",
      "              len((r['user']['description']\n",
      "                   or \"\").split()),\n",
      "              int(r['user']['favourites_count']),\n",
      "              int(r['user']['followers_count']),\n",
      "              int(r['user']['friends_count'])]\n",
      "    tags = model.predict(processed.map(toFeatures)).map(lambda x: codeOf[x])\n",
      "    def store(records):\n",
      "        for record in records:\n",
      "            d, label = record\n",
      "            d['predicted_language'] = label\n",
      "            es.index(index='twitter-predict', doc_type='tweet-enriched', body=d)\n",
      "    store(processed.zip(tags).collect())#.foreach(store)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zkQuorum, topic = \"localhost:2181\", \"twitter_sample\"\n",
      "twitterStream = KafkaUtils.createStream(ssc, zkQuorum,\n",
      "                                  \"spark-streaming-consumer\", {topic: 1})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twitterStream.foreachRDD(tagAndStore)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ssc.start()\n",
      "ssc.awaitTermination()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}